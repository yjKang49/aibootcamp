{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### colab에서 실행하기\n",
        "\n",
        "# reference\n",
        "* 교재: Do it! BERT와 GPT로 배우는 자연어 처리\n",
        "* https://huggingface.co/transformers/v3.5.1/main_classes/tokenizer.html\n",
        "* http://mccormickml.com/2019/11/11/bert-research-ep-1-key-concepts-and-sources/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxiXhiRd0Vb-",
        "outputId": "a7b07390-4d65-4f56-aeee-b200321abbab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip3 install -q transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpnjpf3xfo77"
      },
      "source": [
        "# 330. Transformers 기타 Model들\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9q573FwTYVA"
      },
      "source": [
        "## T5 pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LtoOVcIT7bY",
        "outputId": "28b2b802-6a04-434e-fc83-673b44e7aa9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5TokenizerFast.from_pretrained('t5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eAA2lcWnMppm"
      },
      "outputs": [],
      "source": [
        "def t5_task(text):\n",
        "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "    outputs = model.generate(input_ids)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5I1k-fMNCZR"
      },
      "source": [
        "### 기계 번역"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vBYgxzEP6IIC",
        "outputId": "df60e02a-7a9b-4094-94a6-1057d7a7f18a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ich liebe dich.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"translate English into German: I love you.\"\n",
        "t5_task(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYIcHSClVHf1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hO3UzNB1Ud_v",
        "outputId": "b5d7928b-4a12-4cda-fd17-5298dfb044f8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ich mag Hunde.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"translate English into German: I like dogs.\"\n",
        "t5_task(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "khN1AI0YTRX7",
        "outputId": "b173dc22-a987-4663-9b8d-614e4551b258"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Je vous aime.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"translate English into French: I love you.\"\n",
        "t5_task(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6F3peTodVBFr",
        "outputId": "13987a0a-ddf6-4413-c6b9-9f866fb5a34e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"J'aime les chiens.\""
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"translate English into French:I like dogs.\"\n",
        "t5_task(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmQScf1iNFuJ"
      },
      "source": [
        "### CoLA (The Corpus of Linguistic Acceptability)\n",
        "문장이 문법적으로 맞는지 분류 (이진분류)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1A2sp_sMTg-D",
        "outputId": "b8e0a3e1-eeb4-43ca-806f-a8625c7e5d3c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'unacceptable'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"cola sentence: I bought fruits and.\"\n",
        "t5_task(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PheidAYUUiS1",
        "outputId": "cc5e717c-6e8a-4adc-eae4-89bcf5976f6e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acceptable'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"cola sentence: I bought fruits and vegetables.\"\n",
        "t5_task(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XvsqU6VYVw0m",
        "outputId": "b453b91f-19ae-4049-9274-f8b689693f86"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'acceptable'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"cola sentence: I am learning artificial intelligence today as well. This is fun.\"\n",
        "t5_task(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BA8KkRysV9ol",
        "outputId": "b333293c-c2ce-46a4-c5c2-c54599551eb7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'unacceptable'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text =  \"cola sentence:I am rtificiale today as well. This fun.\"\n",
        "t5_task(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb0GAMl_NUwn"
      },
      "source": [
        "### 질의 응답"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AyN5L5N8UyfP",
        "outputId": "64346438-4b1d-442e-97e4-7a4930bd565b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Mount Everest'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"question: Which is the highest mountain in the world ?\"\n",
        "t5_task(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbP1xeTZNfrU"
      },
      "source": [
        "### STS-B (The Semantic Textual Similarity Benchmark)\n",
        "문장 A 와 B 는 얼마나 유사한가 ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k2ozqqJTVA7C",
        "outputId": "a4c686bc-e88c-4a89-aba3-4fcb64c59ba7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.0'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"stsb sentence1: Cats and dogs are mammals. sentence2: There are four forces in physics.\"\n",
        "t5_task(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "V_KNiKkDWG6d",
        "outputId": "0cf69fb5-c63c-4201-a9e0-ee23f7e3c088"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'5.0'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"stsb sentence1: Cats and dogs are animals. sentence2: Cats and dogs are pets.\"\n",
        "t5_task(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEkLSvvRNmEa"
      },
      "source": [
        "### 문장 요약"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kya_BNT2WN1f",
        "outputId": "d441b11a-f9d4-4f12-ac0c-5748e41faddf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the t5 library is used for reproducing the experiments in Exploring the Limits of'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"\"\"summarize: The t5 library serves primarily as code for reproducing the experiments in Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. In the paper, we demonstrate how to achieve state-of-the-art results on multiple NLP tasks using a text-to-text transformer pre-trained on a large text corpus.\n",
        "The bulk of the code in this repository is used for loading, preprocessing, mixing, and evaluating datasets. It also provides a way to fine-tune the pre-trained models released alongside the publication.\n",
        "The t5 library can be used for future model development by providing useful modules for training and fine-tuning (potentially huge) models on mixtures of text-to-text tasks.\n",
        "\"\"\"\n",
        "t5_task(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N8JX2MlNY0ml",
        "outputId": "d39c7e72-0743-41d4-e35d-9cb6ffc7cb2d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"deep bidirectional transformers for language understanding\" arXiv preprint arXi'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"\"\"summarize: Devlin, Jacob, et al. \"Bert: Pre-training of deep bidirectional\n",
        "transformers for language understanding.\" arXiv preprint\n",
        "arXiv:1810.04805 (2018).\n",
        "\"\"\"\n",
        "t5_task(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJepOQbvYSAI"
      },
      "source": [
        "## 한국어 pre-trained model\n",
        "\n",
        "https://github.com/kiyoungkim1/LMkor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltI8CW4QjWRF"
      },
      "source": [
        "## 한국어 text 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "8cO9ickMX7T4"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast, GPT2LMHeadModel\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('kykim/gpt3-kor-small_based_on_gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('kykim/gpt3-kor-small_based_on_gpt2', pad_token_id=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qj4gEv4GYcZn",
        "outputId": "2e8e0d2d-4216-4933-a756-5c044708f672"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'오늘은 왠지 더 잘할 수 있을 것 같은 느낌이 들어요.'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"오늘은 왠지\"        # 오늘은 왠지라고 입력하니 다음 글('오늘은 왠지 더 잘할 수 있을 것 같은 느낌이 들어요.')을 자동생성해줌. 생성형 \n",
        "\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "input_ids = input_ids[:, 1:]  # remove cls token\n",
        "outputs = model.generate(input_ids)\n",
        "tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMKLo1scigB1"
      },
      "source": [
        "## 한국어 문서 요약"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "JlKcRzRKgxRd",
        "outputId": "cc0fdc2c-971b-4980-da67-749bb63fb1d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
            "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
            "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
            "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "412\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'22일 인수합병 ( m & a ) 업계에 따르면 스마트폰 선행기술 연구개발 ( r & d ) 등 핵심 기능만 남겨둔 채 매각을 시도할 것으로 관측되고 있으며 업계에서는 mc사업부 매각 작업에 속도가 붙을지 관심이 집중되고 있다.'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('kykim/bertshared-kor-base')\n",
        "model = EncoderDecoderModel.from_pretrained('kykim/bertshared-kor-base')\n",
        "\n",
        "# 텍스트 바꿔보기\n",
        "text = '''\n",
        "LG전자가 스마트폰을 담당하는 MC(모바일커뮤니케이션)사업부 분할 및 매각을 위한 법률 자문 업무를 김앤장법률사무소에 맡겼다.\n",
        "MC사업부 매각 작업에 속도가 붙을지 관심이 집중되고 있다.\n",
        "22일 인수합병(M&A)업계에 따르면 LG전자는 최근 MC사업부 분할 후 매각 방안 등을 포괄적으로 검토하기 위해 김앤장을 법률자문사로\n",
        "선임한 것으로 알려졌다.\n",
        "회계·실사 자문은 EY한영회계법인에 맡길 가능성이 큰 것으로 전해졌다. 김앤장 등 자문사들은 사업본부를 분할한 뒤 사업양수도나 분할사업부의 지분 매각,\n",
        "지식재산권(IP) 매각 등을 놓고 검토에 들어간 것으로 알려졌다.\n",
        "업계에서는 LG전자가 MC사업본부를 통매각하기보다는 ‘쪼개기 매각’에 나설 것으로 보고 있다. 스마트폰 선행기술 연구개발(R&D) 등 핵심 기능만 남겨둔 채\n",
        "매각을 시도할 것으로 관측하고 있다. 앞서 권봉석 LG전자 사장은 사내 메시지를 통해 임직원에게 “현재 모든 가능성을 열어 두고 사업 운영방향을 면밀히\n",
        "검토하고 있다”고 밝히며 매각 추진을 암시했다. M&A업계 관계자는 “거래가 성사되기도 전에 사업 전면 재검토를 공식화한 것은 상당히 이례적”이라며\n",
        "“향후 매각이 잘 이뤄지지 않더라도 모바일 사업을 철수하겠다는 배수진을 둔 것으로 보인다”고 설명했다.\n",
        "다만 원매자를 찾기가 쉽지 않을 것이란 전망이 우세하다. LG전자 모바일 사업은 한때 글로벌시장에서 톱5 안에 드는 기술력을 인정받았지만\n",
        "누적 적자만 5조원에 달하고 있다. 업계에서 평가하는 MC사업부의 가치도 5000억원대에서 수조원대까지 편차가 상당히 크다.\n",
        "상대적으로 해외 원매자들의 인수의사가 더 확실한 것으로 알려지고 있다. 북미사업 등 글로벌 시장 확장을 원하는 후발기업들이 주요 대상이다.\n",
        "베트남의 빈그룹과 중국 기업 등이 유력하게 거론된다. 증권업계를 중심으로는 스마트 기기를 연결하는 사물인터넷(IoT) 사업을 염두에 둔 구글,\n",
        "페이스북 같은 미국 정보기술(IT) 기업들도 원매자 후보군으로 꼽고 있다.\n",
        "'''\n",
        "\n",
        "input_ids = tokenizer.encode(text, return_tensors= 'pt')\n",
        "sentence_length = len(input_ids[0])\n",
        "print(sentence_length)\n",
        "\n",
        "outputs = model.generate(\n",
        "            input_ids,\n",
        "            min_length=max(10, int(0.1*sentence_length)),\n",
        "            max_length=min(100, int(0.3*sentence_length))\n",
        "        )\n",
        "\n",
        "tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "wG12I7zyZ14q",
        "outputId": "327875ed-6f0d-4653-bb8f-efa745751a8a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
            "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
            "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
            "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "158\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'문화재청은 고 ( ) 이건희 삼성그룹 회장 유족 측으로부터 상서로운 동물이 지나던 길의 맨 앞부분을 장식했던 것으로 추정되는 서수상 석조각 2점을 기증받았다.'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('kykim/bertshared-kor-base')\n",
        "model = EncoderDecoderModel.from_pretrained('kykim/bertshared-kor-base')\n",
        "\n",
        "text = '''\n",
        "서울 광화문 월대(越臺, 月臺)의 가장 앞부분을 장식했던 것으로 추정되는 석조각이 확인됐다. 삼성가(家)의 도움으로 드러난 이번 유물은 오는 10월까지 예정된 광화문 월대 복원 작업에 활용된다.\n",
        "\n",
        "문화재청은 고(故) 이건희 삼성그룹 회장 유족 측으로부터 상서로운 동물을 본떠 만든 서수상(瑞獸像) 석조각 2점을 기증받았다고 29일 발표했다. 서수상은 부정적인 기운을 쫓아내고 왕실의 권위를 높이려는 기대로 사용해왔다. 유물은 광화문 월대에서 임금이 지나던 길의 맨 앞부분에 있었던 것으로 추정된다. 월대는 궁궐 등 주요 건물 앞에 설치하는 넓은 기단으로, 광화문 월대는 조선시대에 각종 궁궐 행사를 위한 공간으로 활용되다가 일제강점기에 해체됐다.\n",
        "'''\n",
        "\n",
        "input_ids = tokenizer.encode(text, return_tensors= 'pt')\n",
        "sentence_length = len(input_ids[0])\n",
        "print(sentence_length)\n",
        "\n",
        "outputs = model.generate(\n",
        "            input_ids,\n",
        "            min_length=max(10, int(0.1*sentence_length)),\n",
        "            max_length=min(100, int(0.3*sentence_length))\n",
        "        )\n",
        "\n",
        "tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh15pIUZaamy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
