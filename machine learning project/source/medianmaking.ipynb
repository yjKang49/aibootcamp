{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c337f2df87b49e5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:30:40.809897800Z",
     "start_time": "2023-08-08T03:30:39.177967100Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "dfd = pd.read_csv('../data/train.csv', na_values=('#NUM!', '#DIV/0!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "119e1b7bf6c09b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:30:42.143742800Z",
     "start_time": "2023-08-08T03:30:41.518008600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv', na_values=('#NUM!', '#DIV/0!'))\n",
    "samplesubmission = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:30:42.996769700Z",
     "start_time": "2023-08-08T03:30:42.915988500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lnFormaldehyde_tropospheric_HCHO_column_number_density_amf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3361\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lnFormaldehyde_tropospheric_HCHO_column_number_density_amf'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m columns_to_convert \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mlnFormaldehyde_tropospheric_HCHO_column_number_density_amf\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mlogCarbonMonoxide_H2O_column_number_density\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mCloud_surface_albedo\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m columns_to_convert:\n\u001b[1;32m----> 6\u001b[0m     dfd[column] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(dfd[column], errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[39m# Now, check the data types of each column\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(dfd\u001b[39m.\u001b[39mdtypes)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3458\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3458\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3459\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3460\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3363\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3365\u001b[0m \u001b[39mif\u001b[39;00m is_scalar(key) \u001b[39mand\u001b[39;00m isna(key) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhasnans:\n\u001b[0;32m   3366\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lnFormaldehyde_tropospheric_HCHO_column_number_density_amf'"
     ]
    }
   ],
   "source": [
    "columns_to_convert = ['lnFormaldehyde_tropospheric_HCHO_column_number_density_amf',\n",
    "                      'logCarbonMonoxide_H2O_column_number_density',\n",
    "                      'Cloud_surface_albedo']\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    dfd[column] = pd.to_numeric(dfd[column], errors='coerce')\n",
    "\n",
    "# Now, check the data types of each column\n",
    "print(dfd.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "575fd6d5fab3bba9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:30:44.507699700Z",
     "start_time": "2023-08-08T03:30:44.443995300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of lnFormaldehyde_tropospheric_HCHO_column_number_density_amf: 0.192904627\n",
      "Median of logCarbonMonoxide_H2O_column_number_density: 7.618451077\n",
      "Median of Cloud_surface_albedo: 0.272747239\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming dfd is the DataFrame you have and contains the required columns.\n",
    "\n",
    "# Calculate the medians\n",
    "median_value1 = dfd['lnFormaldehyde_tropospheric_HCHO_column_number_density_amf'].median()\n",
    "median_value2 = dfd['logCarbonMonoxide_H2O_column_number_density'].median()\n",
    "median_value3 = dfd['Cloud_surface_albedo'].median()\n",
    "\n",
    "# Print the median values\n",
    "print(\"Median of lnFormaldehyde_tropospheric_HCHO_column_number_density_amf:\", median_value1)\n",
    "print(\"Median of logCarbonMonoxide_H2O_column_number_density:\", median_value2)\n",
    "print(\"Median of Cloud_surface_albedo:\", median_value3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9e2848bf59abd45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:30:45.515713100Z",
     "start_time": "2023-08-08T03:30:45.476816500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of lnFormaldehyde_tropospheric_HCHO_column_number_density_amf: 0.171699825\n",
      "Median of logCarbonMonoxide_H2O_column_number_density: 7.4517882185\n",
      "Median of Cloud_surface_albedo: 0.25727885\n"
     ]
    }
   ],
   "source": [
    "median_value11 = test['lnFormaldehyde_tropospheric_HCHO_column_number_density_amf'].median()\n",
    "median_value22 = test['logCarbonMonoxide_H2O_column_number_density'].median()\n",
    "median_value33 = test['Cloud_surface_albedo'].median()\n",
    "\n",
    "# Print the median values\n",
    "print(\"Median of lnFormaldehyde_tropospheric_HCHO_column_number_density_amf:\", median_value11)\n",
    "print(\"Median of logCarbonMonoxide_H2O_column_number_density:\", median_value22)\n",
    "print(\"Median of Cloud_surface_albedo:\", median_value33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f84f9271fca9fd52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:30:49.412591200Z",
     "start_time": "2023-08-08T03:30:49.388257300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nan_values = dfd['lnFormaldehyde_tropospheric_HCHO_column_number_density_amf'].isna()\n",
    "# NaN 값을 1.25413으로 대체\n",
    "dfd.loc[nan_values, 'lnFormaldehyde_tropospheric_HCHO_column_number_density_amf'] = median_value1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3006a2436826329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:30:50.679311300Z",
     "start_time": "2023-08-08T03:30:50.626453400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nan_values11 = test['lnFormaldehyde_tropospheric_HCHO_column_number_density_amf'].isna()\n",
    "# NaN 값을 1.25413으로 대체\n",
    "test.loc[nan_values11, 'lnFormaldehyde_tropospheric_HCHO_column_number_density_amf'] = median_value11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c596815582bb5c9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:30:51.336518900Z",
     "start_time": "2023-08-08T03:30:51.286881Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nan_values2 = dfd['logCarbonMonoxide_H2O_column_number_density'].isna()\n",
    "# NaN 값을 1.25413으로 대체\n",
    "dfd.loc[nan_values2, 'logCarbonMonoxide_H2O_column_number_density'] = median_value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76474ab93e8b9240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:30:51.932643Z",
     "start_time": "2023-08-08T03:30:51.906711700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nan_values22 = test['logCarbonMonoxide_H2O_column_number_density'].isna()\n",
    "# NaN 값을 1.25413으로 대체\n",
    "test.loc[nan_values22, 'logCarbonMonoxide_H2O_column_number_density'] = median_value22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee87148936d83cff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:30:52.764386100Z",
     "start_time": "2023-08-08T03:30:52.742444500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nan_values3 = dfd['Cloud_surface_albedo'].isna()\n",
    "# NaN 값을 1.25413으로 대체\n",
    "dfd.loc[nan_values3, 'Cloud_surface_albedo'] = median_value3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc05fc38bad244f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:30:53.406199200Z",
     "start_time": "2023-08-08T03:30:53.347355400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nan_values33 = test['Cloud_surface_albedo'].isna()\n",
    "# NaN 값을 1.25413으로 대체\n",
    "test.loc[nan_values33, 'Cloud_surface_albedo'] = median_value33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa6de97ee7a3b293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:30:54.406500700Z",
     "start_time": "2023-08-08T03:30:54.384558800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import re\n",
    "\n",
    "from category_encoders import OneHotEncoder, MEstimateEncoder, GLMMEncoder, OrdinalEncoder, CatBoostEncoder\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold, KFold, TimeSeriesSplit\n",
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, VotingRegressor, StackingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "sns.set_theme(style = 'white', palette = 'colorblind')\n",
    "pal = sns.color_palette('colorblind')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6ed08cd3ca2dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:30:55.221321700Z",
     "start_time": "2023-08-08T03:30:55.149518200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = dfd.copy()\n",
    "y = X.pop('lnemission')\n",
    "\n",
    "seed = 42\n",
    "k = LeaveOneGroupOut()\n",
    "\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0a96c6367693da1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:44:54.969441400Z",
     "start_time": "2023-08-08T03:44:54.896254900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_dropper(x):\n",
    "    return x[['lnFormaldehyde_tropospheric_HCHO_column_number_density_amf', 'longitude', 'week_no', 'month', 'is_covid','logCarbonMonoxide_H2O_column_number_density']]\n",
    "\n",
    "FeatureDropper = FunctionTransformer(feature_dropper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "91a5572d3988d6fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T05:44:57.554647700Z",
     "start_time": "2023-08-08T05:44:57.450924800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def date_processor(x):\n",
    "    x_copy = x.copy()\n",
    "    year_week = pd.to_datetime((x_copy.year * 100 + x_copy.week_no).astype('str') + '0', format = '%Y%W%w')\n",
    "    x_copy['month'] = year_week.dt.month\n",
    "    x_copy['is_covid'] = (x_copy.year == 2020) & (x_copy.month > 2)\n",
    "    return x_copy\n",
    "DateProcessor = FunctionTransformer(date_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a70b1593268c8e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:45:13.190779700Z",
     "start_time": "2023-08-08T03:45:13.154982800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_val_score(model, cv = k, label = ''):\n",
    "    \n",
    "    X = dfd.copy()\n",
    "    y = X.pop('lnemission')\n",
    "    \n",
    "    #initiate prediction arrays and score lists\n",
    "    val_predictions = np.zeros((len(dfd)))\n",
    "    #train_predictions = np.zeros((len(train)))\n",
    "    train_scores, val_scores = [], []\n",
    "    \n",
    "    #training model, predicting prognosis probability, and evaluating log loss\n",
    "    for fold, (dfd_idx, val_idx) in enumerate(cv.split(X, y, X.year)):\n",
    "        \n",
    "        #define train set\n",
    "        X_train = X.iloc[dfd_idx]\n",
    "        y_train = y.iloc[dfd_idx]\n",
    "        \n",
    "        #define validation set\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        #train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #make predictions\n",
    "        train_preds = model.predict(X_train)\n",
    "        val_preds = model.predict(X_val)\n",
    "                  \n",
    "        val_predictions[val_idx] += val_preds\n",
    "        \n",
    "        #evaluate model for a fold\n",
    "        train_score = mean_squared_error(y_train, train_preds, squared = False)\n",
    "        val_score = mean_squared_error(y_val, val_preds, squared = False)\n",
    "        \n",
    "        #append model score for a fold to list\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "    \n",
    "    print(f'Val Score: {np.mean(val_scores):.5f} ± {np.std(val_scores):.5f} | Train Score: {np.mean(train_scores):.5f} ± {np.std(train_scores):.5f} | {label}')\n",
    "    \n",
    "    return val_scores, val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba1c4fba0f7035b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:45:14.866267900Z",
     "start_time": "2023-08-08T03:45:14.736708700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_list, oof_list = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "models = [\n",
    "    ('ridge', Ridge(random_state = seed)),\n",
    "    ('rf', RandomForestRegressor(random_state = seed)),\n",
    "    ('et', ExtraTreesRegressor(random_state = seed)),\n",
    "    ('xgb', XGBRegressor(random_state = seed)),\n",
    "    ('lgb', LGBMRegressor(random_state = seed)),\n",
    "    ('cb', CatBoostRegressor(random_state = seed, verbose = 0)),\n",
    "    ('gb', GradientBoostingRegressor(random_state = seed)),\n",
    "    ('hgb', HistGradientBoostingRegressor(random_state = seed))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7704e353ba360162",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:52:42.857663300Z",
     "start_time": "2023-08-08T03:45:15.709150300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Score: 1.91815 ± 0.02285 | Train Score: 1.91012 ± 0.01090 | ridge\n",
      "Val Score: 0.49656 ± 0.02053 | Train Score: 0.17428 ± 0.00220 | rf\n",
      "Val Score: 0.57560 ± 0.01042 | Train Score: 0.02754 ± 0.00794 | et\n",
      "Val Score: 0.56313 ± 0.02004 | Train Score: 0.49042 ± 0.00691 | xgb\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 833\n",
      "[LightGBM] [Info] Number of data points in the train set: 52682, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 3.199796\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 831\n",
      "[LightGBM] [Info] Number of data points in the train set: 52682, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 3.301991\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 833\n",
      "[LightGBM] [Info] Number of data points in the train set: 52682, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 3.252410\n",
      "Val Score: 1.23730 ± 0.01632 | Train Score: 1.19009 ± 0.00803 | lgb\n",
      "Val Score: 1.17037 ± 0.02006 | Train Score: 1.10806 ± 0.00762 | cb\n",
      "Val Score: 1.34505 ± 0.01131 | Train Score: 1.33281 ± 0.01346 | gb\n",
      "Val Score: 1.19814 ± 0.01345 | Train Score: 1.15150 ± 0.00461 | hgb\n"
     ]
    }
   ],
   "source": [
    "for (label, model) in models:\n",
    "     score_list[label], oof_list[label] = cross_val_score(\n",
    "         make_pipeline(DateProcessor, FeatureDropper, model),\n",
    "         label = label,\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "205b84ba7c0f37df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:55:57.130001200Z",
     "start_time": "2023-08-08T03:53:42.911157200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(DateProcessor, FeatureDropper, RandomForestRegressor(random_state = seed))\n",
    "\n",
    "model.fit(X, y)\n",
    "prediction = model.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a0aea999841150f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T03:56:44.586226500Z",
     "start_time": "2023-08-08T03:56:41.369017200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['lnemission'] = prediction\n",
    "test.to_csv('submission5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b32a476e704e7ef",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
